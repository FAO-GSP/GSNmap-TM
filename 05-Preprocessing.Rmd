# The training dataset and basic computations in **R**

In this chapter, the datasets used in this technical manual are presented. They were adapted for educational purposes by the GSP Secretariat.
The tutorial provided in this chapter is for demonstration purposes and is meant for users with no prior experience in **R**. 
Thus, the instructions also serve as a continuation of the basic introduction to the functioning of **R** and *RStudio* given in [Chapter 3](https://fao-gsp.github.io/GSNmap-TM/setting-up-the-software-environment.html#use-of-r-rstudio-and-r-packages).

Instructions are given on how to:

1. Generate user-defined variables, 
2. Set the working directory and load necessary packages, 
3. Import national data to *RStudio*

Users with prior experience may skip this chapter and go directly to Chapters 6 to 9 which cover all the necessary steps from data preparation to mapping and reporting.

 
## Study area and training material

The study area is located in the southeast of the Pampas Region, in Argentina, from the foothills of the Ventania and Tandilia hill systems, until the southern coasts of the Buenos Aires Province. 
To illustrate the different processes of this Technical Manual, we use three datasets from this region:

* Georeferenced topsoil data
  * Chemical soil properties
  * Physical soil properties
* Soil profile data

### Georeferenced topsoil data

These data were collected in 2011 by the National Institute of Agriculture Technology and Faculty of Agricultural Science of the National University of Mar del Plata  (Unidad Integrada INTA-FCA) to map the status of soil nutrients in the Argentinian Pampas [@sainz2019]. The modified dataset is derived from a subset of 118 locations and covers the target depth of 0-30 cm. It is structured in two different spreadsheets that contain *soil chemical properties* (soil_chem_data030.csv) and *soil physical properties* (soil_phys_data030.csv). All datasets are located in the `01-Data` folder in the training material `Digital-Soil-Mapping` folder. 
The soil chemical properties spreadsheet provides data from laboratories with point coordinates (lat/long) together with data on available Phosphorus (p_bray, in ppm), available Potassium (k, in ppm), and total nitrogen (tn, in Percent) (see Table \@ref(tab:table2)).  

```{r table2, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)

data <- read_csv("Digital-Soil-Mapping/01-Data/soil_chem_data030.csv")
kable(booktabs = T, data[1:10,], col.names = gsub("[.]", " ", names(data)), caption = 'Dataset with coordinates for chemical soil properties.', digits = c(0,6,6,2,2,2,1)) %>%
kable_classic(full_width = F) %>%
  #kable_styling(latex_options = 'striped', font_size = 10) %>%
footnote(general = "Only the ten first rows are shown.", general_title = "")
```

The spreadsheet with soil physical data contains data on soil texture for clay (clay_0_30, in g/kg), silt (silt_0_30, in g/kg), and sand (sand_0_30, in g/kg) (see Table \@ref(tab:table22)).

```{r table22, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)

data <- read_csv("Digital-Soil-Mapping/01-Data/soil_phys_data030.csv")
kable(booktabs = T, data[1:10,], col.names = gsub("[.]", " ", names(data)), caption = 'Dataset with coordinates for physical soil properties.',  digits = c(0,6,6,2,2,2,1)) %>%
kable_classic(full_width = F) %>%
  #kable_styling(latex_options = 'striped', font_size = 10) %>%
footnote(general = "Only the ten first rows are shown.", general_title = "")
```

The distribution of points is shown in the following map for available Phosphorus values as points. This dataset is used in [Chapter 8](https://fao-gsp.github.io/GSNmap-TM/step-3-mapping-continuous-soil-properties.html) for mapping.


```{r exploratory1, eval=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(mapview)

mapviewOptions(fgb = FALSE)

data <- 
  read_csv("Digital-Soil-Mapping/01-Data/soil_chem_data030.csv")
s <- st_as_sf(data, coords = c("x", "y"), crs = 4326)
mapview(s, zcol = "p_bray", cex = 2.5, lwd = 0)
```

### Soil profile data

Finally, the third dataset belongs to the Soil Information System of Argentina ([SISINTA](http://sisinta.inta.gob.ar/), @Olmedo2017) which contains soil profiles collected from the sixties to recently years for soil survey purposes. The data can be fetched using the package [SISINTAR](https://github.com/INTA-Suelos/SISINTAR#readme). Table \@ref(tab:table4) shows a subset of the data, and the map presents the distribution of soil profiles for the study area. Soil profile data consists of measurements of soil organic carbon (soc, in Percent), soil pH (ph_h2o), available Potassium (k), bulk density (bd, in g/cm^3^), cation exchange capacity (cec, in cmol~c~/100g). This dataset is used in this chapter to illustrate the preprocessing steps required for data that come from soil profiles.

```{r table4, echo=FALSE, message=FALSE, warning=FALSE}
data <- read_csv("Digital-Soil-Mapping/01-Data/soil_profile_data.csv")
kable(booktabs = T, data[c(1:10),1:10], col.names = gsub("[.]", " ", names(data)[1:10]), caption = 'Soil profile dataset.',  digits = c(0,0,6,6,0,0,0,1,1,2)) %>%
kable_classic(full_width = F) %>%
# kable_styling("scale_down") %>%
footnote(general = "Only ten rows are shown.", general_title = "")
```

```{r exploratory data 3, eval=TRUE, message=FALSE, warning=FALSE}

library(tidyverse)
library(sf)
library(mapview)

mapviewOptions(fgb = FALSE)
data <- 
  read_csv("Digital-Soil-Mapping/01-Data/soil_profile_data.csv")
s <- data %>% filter(top==0)
s <- st_as_sf(s, coords = c("x", "y"), crs = 4326)
mapview(s, zcol = "k", cex = 2.5, lwd = 0)
```

## Format requirements of soil data {#preproc}

Soil data generally consists of measurements at a specific geographical location, time and soil depth. Therefore, it is necessary to arrange the data following the format shown in Table \@ref(tab:data1).

```{r data1, echo = FALSE, message=F, warning=F}

library(dplyr)
library(kableExtra)
dt <- read.csv("tables/Table_5.1.csv", sep = ",")
kable(booktabs = T, dt, col.names = gsub("[.]", " ", names(dt)), caption = 'Example format of a database.') %>%
kable_classic(full_width = F) %>%
  #kable_styling(latex_options = 'striped', font_size = 10) %>%
footnote(general = "Profile ID = unique profile identifier, Horizon ID = unique layer identifier, Lat = latitude in decimal degrees, Long = longitude in decimal degrees, Year = sampling year, Top = upper limit of the layer in cm, Bottom = lower limit of the layer in cm, cec = Cation Exchange Capacity (cmol_c/kg), ph = pH in water, clay = Clay (g/100g soil), silt = Silt (g/100g soil), sand = Sand ((g/100g soil), soc = Soil Organic Carbon (g/100g soil), bd = Bulk Density (g/cm3).", threeparttable = TRUE)%>%
 kable_styling(font_size =5) 
  #add_header_above(c("Approach for developing national information on soil erosion" = 2), bold = T) %>% 
  #kableExtra::group_rows(group_label = "Approach for developing national information on soil erosion", start_row = 1, end_row = 3) %>%
  #kableExtra::group_rows(group_label = "Input data preparation (see Table 3.1)", start_row = 4, end_row = 10) %>% 
  #kableExtra::group_rows(group_label = "Expected outputs", start_row = 11, end_row = 19)
#knitr::kable()

```

## Pre-processing steps
Soil data is often arranged in a different way which requires specific pre-processing steps to reach the format. On the way towards a formatted database, common issues such as, arranging the data format, fixing soil horizon depth consistency, detecting unusual soil property measurements, can be solved. Here, common issues and examples are given on how to carry out some basic data handling steps in *RStudio*.

### Set the scene (set working directory, packages, load data)

Let's open *RStudio*. Whenever starting to work on a project or task, it is necessary to set the *working directory* (WD). The WD is the folder path that is used by **R** to save the output, for instance a plot or a table that was generated while working in **R**. Thus, the WD is central since it dictates where the files and calculations can be found afterwards. As it is so important, there are multiple ways of setting the WD. 
One option is to right click on 'Session' menu > 'Set working directory ...' and select either 'To Source File Location' (then the WD corresponds to the file path where the Script is saved to) or 'Choose Directory...'. Then, the user can browse to the folder that should be the WD. 

In this manual we propose an alternative way that allows for more customization and flexibility since sometimes multiple WDs are needed to for instance save the final map in a different folder than the covariates. Since the file paths differ depending on where you stored the file on your computer, it is crucial to identify the correct file path. This can be done by accessing the *file explorer*. There you can browse to your training material folder and then right-click on the bar highlighted in red in the Figure \@ref(fig:explorer).

```{r explorer, echo = FALSE, fig.cap = "Get file path from file explorer.", out.width='100%'}
knitr::include_graphics("images/file-explorer.png")

```

The file path will appear with the following format: `C:\Users\GSNmap-TM\Digital-Soil-Mapping`. In order to enable **R** to read this as file path, it is necessary to replace the `\` by `/`. The resulting file path should look similar to this one: `C:/Users/GSNmap-TM/Digital-Soil-Mapping`. Once this is done, we can assign the file path that represents the WD file path to an **R** object. This is done by defining a character value (in this case the file path) on the right side of the arrow (`<-`) and name the **R** object on the left side (wd) (see code). Once this is done we use the function `setwd()` to set the WD to the file path that is specified in the object `wd`.

```{r, echo = T, eval = F}
# 0 - User-defined variables ====================================

wd <- 'C:/Users/hp/Documents/GitHub/Digital-Soil-Mapping'
#wd <- "C:/GIT/Digital-Soil-Mapping"

# 1 - Set working directory and load necessary packages =========
setwd(wd) # change the path accordingly
```

An alternative and more automatic approach for setting the working directory makes use of the rstudioapi package, which provides functions for interacting with RStudio's API (Application Programming Interface). The code below first sets the working directory to the directory containing the active document (in this case the script). Then, the second line of code it changes the working directory to the parent directory using the ".." specification.

```{r, echo = T, eval = F}

#Set the working directory automatically using rstudioapi 
# It is important to note that the directory is set to the folder
#containing the script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# The ".." is used to go up a directory 
#(in this case our project folder)
setwd("..")
```


Next to in-built base R functions, there is a vast amount of so-called packages that extend the functionalities of **R** and allow the use of **R** for a broad range of purposes. For data handling and management, the `tidyverse` package and its dependencies offer a great help. To load packages into the *RStudio* session, the `library` function is used. However, if the package is not installed, it is necessary to use the `install.packages` function first.

```{r, echo = T, eval = T}

#install.packages(tidyverse)
library(readxl)
library(tidyverse)
library(dplyr)

# load in data
data <- 
  read_csv("Digital-Soil-Mapping/01-Data/soil_chem_data030.csv")
head(data)

```


For further guidance and more in-depth techniques to administer and handle soil data in **R**, it is recommended to check the GitHub repository on soil database management of the GSP: [FAO-GSP Soil DB](https://github.com/FAO-GSP/SoilDB). There, not only training data but also extensive example codes are available.
For now, we continue working with the example dataset and assume that the dataset you are using complies with the format specified at the beginning.